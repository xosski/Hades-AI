"""
Exploit Seek & Share Tab for HadesAI - AI Enhanced
Provides UI for P2P exploit searching and AI-powered vulnerability testing
"""

from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QGroupBox, QLabel, QPushButton,
    QLineEdit, QTextEdit, QTableWidget, QTableWidgetItem, QProgressBar,
    QComboBox, QCheckBox, QSpinBox, QTabWidget, QMessageBox, QListWidget,
    QListWidgetItem, QSplitter, QStatusBar, QFormLayout
)
from PyQt6.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt6.QtGui import QFont, QColor, QIcon
import json
import time
import logging
from typing import Optional, Callable, Dict, List
from p2p_exploit_sharing import (
    P2PExploitSharer, ExploitSeeker, ExploitFinding
)

logger = logging.getLogger("ExploitSeekTab")

try:
    from comprehensive_exploit_seeker import UnifiedExploitKnowledge
    HAS_UNIFIED_SEEKER = True
except ImportError:
    UnifiedExploitKnowledge = None
    HAS_UNIFIED_SEEKER = False

try:
    from ai_vulnerability_tester_fixed import AIVulnerabilityTester
    HAS_AI_TESTER = True
except ImportError:
    try:
        from ai_vulnerability_tester import AIVulnerabilityTester
        HAS_AI_TESTER = True
    except ImportError:
        AIVulnerabilityTester = None
        HAS_AI_TESTER = False


class SeekWorker(QThread):
    """Background worker for exploit seeking"""
    finished = pyqtSignal(dict)
    progress = pyqtSignal(str)
    error = pyqtSignal(str)
    
    def __init__(self, seeker: ExploitSeeker, target_url: str):
        super().__init__()
        self.seeker = seeker
        self.target_url = target_url
        self.setObjectName("SeekWorker")
    
    def run(self):
        try:
            self.progress.emit(f"Seeking exploits for {self.target_url}...")
            result = self.seeker.seek_and_attempt(
                self.target_url,
                callback=self._progress_callback
            )
            if result:
                self.finished.emit(result)
            else:
                self.error.emit("No result returned from seek")
        except Exception as e:
            self.error.emit(str(e))
    
    def _progress_callback(self, result: dict):
        if result:
            self.progress.emit(f"Exploit attempts: {len(result.get('attempts', []))}")


class UnifiedSeekWorker(QThread):
    """Background worker for unified exploit seeking from all sources"""
    finished = pyqtSignal(dict)
    progress = pyqtSignal(str)
    enumeration_progress = pyqtSignal(str)  # Per-source progress
    error = pyqtSignal(str)
    
    def __init__(self, unified_seeker, target_url: str):
        super().__init__()
        self.unified_seeker = unified_seeker
        self.target_url = target_url
        self.setObjectName("UnifiedSeekWorker")
    
    def run(self):
        try:
            self.progress.emit("Initiating comprehensive exploit enumeration...")
            self.enumeration_progress.emit("Searching 7 knowledge sources...")
            
            # Get exploits from all sources
            exploits = self.unified_seeker.seek_all_exploits(self.target_url)
            
            # Get source statistics
            source_stats = self.unified_seeker.get_source_stats(exploits)
            source_info = "\n".join([f"  {src}: {cnt}" for src, cnt in source_stats.items()])
            
            self.progress.emit(f"Enumeration complete: {len(exploits)} total exploits found")
            self.enumeration_progress.emit(f"Source breakdown:\n{source_info}")
            
            # Convert exploits to attempts format (dicts with all details)
            attempts = []
            for i, exploit in enumerate(exploits, 1):
                attempt = {
                    'exploit_id': exploit.get('id', f'exploit_{i}'),
                    'exploit_type': exploit.get('type', 'Unknown'),
                    'severity': exploit.get('severity', 'Medium'),
                    'payload': exploit.get('payload', ''),
                    'description': exploit.get('description', ''),
                    'success': exploit.get('success', False),
                    'confidence': exploit.get('confidence', 0.5),
                    'source': exploit.get('source', 'Unknown'),
                    'impact': exploit.get('impact', ''),
                    'remediation': exploit.get('remediation', ''),
                    'timestamp': exploit.get('timestamp', time.time())
                }
                attempts.append(attempt)
            
            # Prepare result
            result = {
                'target': self.target_url,
                'status': 'completed' if len(attempts) > 0 else 'no_exploits_found',
                'attempts': attempts,
                'timestamp': time.time(),
                'total_exploits': len(attempts),
                'sources': source_stats,
                'enumeration_complete': True
            }
            
            self.finished.emit(result)
        except Exception as e:
            import traceback
            error_detail = f"Comprehensive seek error: {str(e)}\n{traceback.format_exc()}"
            logger.error(error_detail)
            self.error.emit(error_detail)


class AIVulnerabilityWorker(QThread):
    """Background worker for AI-powered vulnerability testing"""
    finished = pyqtSignal(dict)
    progress = pyqtSignal(str)
    error = pyqtSignal(str)
    
    def __init__(self, tester: 'AIVulnerabilityTester', target_url: str, test_categories: List[str] = None):
        super().__init__()
        self.tester = tester
        self.target_url = target_url
        self.test_categories = test_categories or ['injection', 'authentication', 'configuration']
        self.setObjectName("AIVulnerabilityWorker")
    
    def run(self):
        try:
            result = self.tester.test_website(
                self.target_url,
                test_categories=self.test_categories,
                callback=lambda msg: self.progress.emit(msg)
            )
            self.finished.emit(result)
        except Exception as e:
            import traceback
            error_detail = f"AI Vulnerability Test Error: {str(e)}\n{traceback.format_exc()}"
            logger.error(error_detail)
            self.error.emit(error_detail)


class ExploitSeekTab(QWidget):
    """Tab for exploit seeking and P2P sharing - Enhanced with AI Testing"""
    
    def __init__(self, parent=None, exploit_sharer: P2PExploitSharer = None, hades_ai=None):
        super().__init__(parent)
        self.exploit_sharer = exploit_sharer or P2PExploitSharer()
        self.hades_ai = hades_ai
        self.exploit_seeker = ExploitSeeker(self.exploit_sharer)
        
        # Use unified seeker if available
        self.unified_seeker = None
        if HAS_UNIFIED_SEEKER and hades_ai:
            self.unified_seeker = UnifiedExploitKnowledge(hades_ai, exploit_sharer)
        
        # Initialize AI vulnerability tester
        self.ai_tester = None
        if HAS_AI_TESTER:
            self.ai_tester = AIVulnerabilityTester(hades_ai)
        
        self.seek_worker = None
        self.ai_worker = None
        self.current_search_results = {}
        self.current_ai_results = {}
        self.init_ui()
        
        # Auto-refresh shared exploits
        self.refresh_timer = QTimer()
        self.refresh_timer.timeout.connect(self._refresh_shared_exploits)
        self.refresh_timer.start(5000)  # Every 5 seconds
    
    def closeEvent(self, event):
        """Cleanup threads on close"""
        self.refresh_timer.stop()
        if self.seek_worker and self.seek_worker.isRunning():
            self.seek_worker.quit()
            self.seek_worker.wait()
        if self.ai_worker and self.ai_worker.isRunning():
            self.ai_worker.quit()
            self.ai_worker.wait()
        super().closeEvent(event)
    
    def init_ui(self):
        layout = QVBoxLayout(self)
        
        # ===== SEEK SECTION =====
        seek_group = QGroupBox("ðŸ” Exploit Seeker + ðŸ¤– AI Tester")
        seek_layout = QVBoxLayout(seek_group)
        
        # URL input and buttons
        url_layout = QHBoxLayout()
        url_layout.addWidget(QLabel("Target URL:"))
        self.url_input = QLineEdit()
        self.url_input.setPlaceholderText("https://target.com or paste link here")
        url_layout.addWidget(self.url_input)
        
        # Main SEEK button (prominent)
        self.seek_button = QPushButton("âš¡ SEEK EXPLOITS")
        self.seek_button.setStyleSheet("""
            QPushButton {
                background-color: #ff4444;
                color: white;
                font-weight: bold;
                font-size: 12px;
                padding: 8px;
                border-radius: 4px;
            }
            QPushButton:hover {
                background-color: #ff2222;
            }
            QPushButton:pressed {
                background-color: #cc0000;
            }
        """)
        self.seek_button.clicked.connect(self._start_seek)
        self.seek_button.setCursor(Qt.CursorShape.PointingHandCursor)
        url_layout.addWidget(self.seek_button)
        
        # AI Vulnerability Testing button
        self.ai_test_button = QPushButton("ðŸ¤– AI TEST")
        self.ai_test_button.setStyleSheet("""
            QPushButton {
                background-color: #9C27B0;
                color: white;
                font-weight: bold;
                font-size: 12px;
                padding: 8px;
                border-radius: 4px;
            }
            QPushButton:hover {
                background-color: #7B1FA2;
            }
            QPushButton:pressed {
                background-color: #6A1B9A;
            }
        """)
        self.ai_test_button.clicked.connect(self._start_ai_test)
        self.ai_test_button.setCursor(Qt.CursorShape.PointingHandCursor)
        self.ai_test_button.setEnabled(HAS_AI_TESTER)
        self.ai_test_button.setToolTip("Run AI-powered vulnerability tests on authorized website")
        url_layout.addWidget(self.ai_test_button)
        
        # Auto-attempt checkbox
        self.auto_attempt_check = QCheckBox("Auto-Attempt")
        self.auto_attempt_check.setChecked(True)
        self.auto_attempt_check.setToolTip("Automatically attempt discovered exploits")
        url_layout.addWidget(self.auto_attempt_check)
        
        seek_layout.addLayout(url_layout)
        
        # Search options
        options_layout = QHBoxLayout()
        options_layout.addWidget(QLabel("Severity Filter:"))
        self.severity_filter = QComboBox()
        self.severity_filter.addItems(["All", "Critical", "High", "Medium", "Low"])
        options_layout.addWidget(self.severity_filter)
        
        options_layout.addWidget(QLabel("Max Attempts:"))
        self.max_attempts = QSpinBox()
        self.max_attempts.setValue(10)
        self.max_attempts.setRange(1, 100)
        options_layout.addWidget(self.max_attempts)
        
        options_layout.addWidget(QLabel("Timeout (sec):"))
        self.timeout_spin = QSpinBox()
        self.timeout_spin.setValue(30)
        self.timeout_spin.setRange(5, 300)
        options_layout.addWidget(self.timeout_spin)
        
        options_layout.addStretch()
        seek_layout.addLayout(options_layout)
        
        # Progress bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        seek_layout.addWidget(self.progress_bar)
        
        # Status label
        self.status_label = QLabel("Ready")
        self.status_label.setStyleSheet("color: #4CAF50; font-weight: bold;")
        seek_layout.addWidget(self.status_label)
        
        layout.addWidget(seek_group)
        
        # ===== RESULTS TABS =====
        results_tabs = QTabWidget()
        
        # TAB 1: Search Results
        results_widget = QWidget()
        results_layout = QVBoxLayout(results_widget)
        
        self.results_table = QTableWidget()
        self.results_table.setColumnCount(6)
        self.results_table.setHorizontalHeaderLabels([
            "Exploit Type", "Severity", "Status", "Payload", "Description", "Source"
        ])
        self.results_table.setColumnWidth(0, 150)
        self.results_table.setColumnWidth(1, 80)
        self.results_table.setColumnWidth(2, 100)
        self.results_table.setColumnWidth(3, 150)
        self.results_table.setColumnWidth(4, 200)
        self.results_table.setColumnWidth(5, 100)
        results_layout.addWidget(self.results_table)
        results_tabs.addTab(results_widget, "Search Results")
        
        # TAB 2: Detailed Output
        self.details_output = QTextEdit()
        self.details_output.setReadOnly(True)
        self.details_output.setFont(QFont("Courier", 9))
        results_tabs.addTab(self.details_output, "Details")
        
        # TAB 3: Network Sharing
        network_widget = QWidget()
        network_layout = QVBoxLayout(network_widget)
        
        self.stats_label = QLabel("Network Stats: Loading...")
        network_layout.addWidget(self.stats_label)
        
        button_layout = QHBoxLayout()
        share_btn = QPushButton("ðŸ“¤ Share Results")
        share_btn.clicked.connect(self._share_to_network)
        button_layout.addWidget(share_btn)
        
        export_btn = QPushButton("ðŸ’¾ Export Results")
        export_btn.clicked.connect(self._export_results)
        button_layout.addWidget(export_btn)
        
        # Security report export button for HackerOne/bug bounty
        report_btn = QPushButton("ðŸ”’ Security Report")
        report_btn.setStyleSheet("""
            QPushButton {
                background-color: #1976d2;
                color: white;
                font-weight: bold;
                padding: 6px;
                border-radius: 3px;
            }
            QPushButton:hover {
                background-color: #1565c0;
            }
        """)
        report_btn.setToolTip("Export professional security report (JSON/Markdown/HTML) for HackerOne or bug bounty")
        report_btn.clicked.connect(self._export_security_report)
        button_layout.addWidget(report_btn)
        
        clear_btn = QPushButton("ðŸ—‘ï¸ Clear Results")
        clear_btn.clicked.connect(self._clear_results)
        button_layout.addWidget(clear_btn)
        
        network_layout.addLayout(button_layout)
        
        self.network_list = QListWidget()
        network_layout.addWidget(QLabel("Network Exploits:"))
        network_layout.addWidget(self.network_list)
        
        results_tabs.addTab(network_widget, "Network")
        
        layout.addWidget(results_tabs)
        
        self.setLayout(layout)
    
    def _start_seek(self):
        """Start exploit seeking"""
        target = self.url_input.text().strip()
        
        if not target:
            QMessageBox.warning(self, "Input Required", "Please enter a target URL")
            return
        
        if not target.startswith(('http://', 'https://')):
            target = f'https://{target}'
        
        self.seek_button.setEnabled(False)
        self.seek_button.setText("âš¡ SEEKING...")
        self.progress_bar.setVisible(True)
        self.status_label.setText("ðŸ” Seeking exploits...")
        self.status_label.setStyleSheet("color: #2196F3; font-weight: bold;")
        
        # Use unified seeker if available
        if self.unified_seeker:
            self.seek_worker = UnifiedSeekWorker(self.unified_seeker, target)
            self.seek_worker.enumeration_progress.connect(self._on_enumeration_progress)
        else:
            self.seek_worker = SeekWorker(self.exploit_seeker, target)
        
        self.seek_worker.finished.connect(self._on_seek_finished)
        self.seek_worker.progress.connect(self._on_seek_progress)
        self.seek_worker.error.connect(self._on_seek_error)
        self.seek_worker.start()
    
    def _start_ai_test(self):
        """Start AI vulnerability testing"""
        if not self.ai_tester:
            QMessageBox.warning(self, "Not Available", "AI Vulnerability Tester not initialized")
            return
        
        target_url = self.url_input.text().strip()
        if not target_url:
            QMessageBox.warning(self, "Input Required", "Please enter a target URL")
            return
        
        # Ensure URL has protocol
        if not target_url.startswith(('http://', 'https://')):
            target_url = f'https://{target_url}'
            self.url_input.setText(target_url)
        
        # Disable button and show progress
        self.ai_test_button.setEnabled(False)
        self.ai_test_button.setText("ðŸ¤– TESTING...")
        self.progress_bar.setVisible(True)
        self.progress_bar.setMaximum(0)
        self.status_label.setText("ðŸ¤– Running AI vulnerability tests...")
        self.status_label.setStyleSheet("color: #9C27B0; font-weight: bold;")
        
        # Create and start worker with all available test categories
        all_categories = [
            'injection', 'authentication', 'configuration', 'headers',
            'cookie_security', 'access_control', 'api_security', 'methods'
        ]
        self.ai_worker = AIVulnerabilityWorker(
            self.ai_tester,
            target_url,
            test_categories=all_categories
        )
        self.ai_worker.finished.connect(self._on_ai_test_finished)
        self.ai_worker.progress.connect(self._on_ai_test_progress)
        self.ai_worker.error.connect(self._on_ai_test_error)
        self.ai_worker.start()
    
    def _on_seek_finished(self, result: dict):
        """Handle seek completion"""
        try:
            self.current_search_results = result
            
            # Update UI
            self.seek_button.setEnabled(True)
            self.seek_button.setText("âš¡ SEEK EXPLOITS")
            self.progress_bar.setVisible(False)
            
            attempts = result.get('attempts', [])
            successful = sum(1 for a in attempts if a.get('success'))
            
            if result['status'] == 'exploited':
                self.status_label.setText(f"âœ… SUCCESS! Exploited with {successful} successful attempts")
                self.status_label.setStyleSheet("color: #4CAF50; font-weight: bold;")
            elif attempts:
                self.status_label.setText(f"âš ï¸  Found {len(attempts)} exploits, {successful} successful")
                self.status_label.setStyleSheet("color: #ff9800; font-weight: bold;")
            else:
                self.status_label.setText("âŒ No exploits found for target")
                self.status_label.setStyleSheet("color: #f44336; font-weight: bold;")
            
            # Display results
            self._display_results(result)
        except Exception as e:
            self.status_label.setText(f"Error: {str(e)}")
            self.status_label.setStyleSheet("color: #f44336; font-weight: bold;")
    
    def _on_ai_test_finished(self, result: dict):
        """Handle AI test completion"""
        try:
            self.current_ai_results = result
            
            # Update UI
            self.ai_test_button.setEnabled(True)
            self.ai_test_button.setText("ðŸ¤– AI TEST")
            self.progress_bar.setVisible(False)
            
            # Handle both old and new key names
            vuln_count = result.get('total_vulnerabilities', result.get('vulnerabilities_found', 0))
            total_tests = result.get('total_tests_run', result.get('total_tests', 0))
            
            if vuln_count > 0:
                self.status_label.setText(
                    f"ðŸš¨ AI TEST COMPLETE: {vuln_count} vulnerabilities in {total_tests} tests"
                )
                self.status_label.setStyleSheet("color: #ff5722; font-weight: bold;")
            else:
                self.status_label.setText(
                    f"âœ… AI TEST COMPLETE: No vulnerabilities found ({total_tests} tests)"
                )
                self.status_label.setStyleSheet("color: #4CAF50; font-weight: bold;")
            
            # Display AI test results
            self._display_ai_results(result)
            
        except Exception as e:
            self.status_label.setText(f"Error: {str(e)}")
            self.status_label.setStyleSheet("color: #f44336; font-weight: bold;")
    
    def _on_seek_progress(self, message: str):
        """Handle progress update"""
        self.status_label.setText(message)
    
    def _on_ai_test_progress(self, message: str):
        """Handle AI test progress"""
        self.status_label.setText(message)
        
        # Also append to details output so user sees progress
        current = self.details_output.toPlainText()
        if current and not current.endswith('\n'):
            current += '\n'
        self.details_output.setText(current + message)
        
        # Auto-scroll to bottom
        self.details_output.verticalScrollBar().setValue(
            self.details_output.verticalScrollBar().maximum()
        )
    
    def _on_enumeration_progress(self, message: str):
        """Handle enumeration progress"""
        current = self.details_output.toPlainText()
        if current and not current.endswith('\n\n'):
            current += '\n'
        self.details_output.setText(current + message)
        self.details_output.verticalScrollBar().setValue(
            self.details_output.verticalScrollBar().maximum()
        )
    
    def _on_seek_error(self, error: str):
        """Handle seek error"""
        self.seek_button.setEnabled(True)
        self.seek_button.setText("âš¡ SEEK EXPLOITS")
        self.progress_bar.setVisible(False)
        self.status_label.setText(f"âŒ Error: {error}")
        self.status_label.setStyleSheet("color: #f44336; font-weight: bold;")
        QMessageBox.critical(self, "Seek Error", error)
    
    def _on_ai_test_error(self, error: str):
        """Handle AI test error"""
        self.ai_test_button.setEnabled(True)
        self.ai_test_button.setText("ðŸ¤– AI TEST")
        self.progress_bar.setVisible(False)
        self.status_label.setText(f"âŒ AI Test Error: {error}")
        self.status_label.setStyleSheet("color: #f44336; font-weight: bold;")
        QMessageBox.critical(self, "AI Test Error", error)
    
    def _display_results(self, result: dict):
        """Display search results in table"""
        try:
            self.results_table.setRowCount(0)
            
            attempts = result.get('attempts', [])
            for attempt in attempts:
                row = self.results_table.rowCount()
                self.results_table.insertRow(row)
                
                exploit_type = attempt.get('exploit_type', 'Unknown')
                success = "âœ… Success" if attempt.get('success') else "âŒ Failed"
                severity = attempt.get('severity', 'Medium')
                source = attempt.get('source', 'Unknown')
                
                items = [
                    exploit_type,
                    severity,
                    success,
                    attempt.get('payload', '')[:50],
                    attempt.get('description', '')[:50],
                    source
                ]
                
                for col, item in enumerate(items):
                    cell = QTableWidgetItem(str(item))
                    if success == "âœ… Success":
                        cell.setBackground(QColor(100, 255, 100))
                    self.results_table.setItem(row, col, cell)
            
            # Detailed output
            details = f"""
EXPLOIT SEEK RESULTS
Target: {result.get('target', 'Unknown')}
Status: {result.get('status', 'Unknown').upper()}
Total Exploits Found: {len(attempts)}
Timestamp: {time.ctime(result.get('timestamp', time.time()))}

SUMMARY:
Total: {len(attempts)}
Successful: {sum(1 for a in attempts if a.get('success'))}
Failed: {sum(1 for a in attempts if not a.get('success'))}
"""
            
            for i, attempt in enumerate(attempts, 1):
                details += f"""
EXPLOIT #{i}
Type: {attempt.get('exploit_type', 'Unknown')}
Severity: {attempt.get('severity', 'Unknown')}
Status: {'âœ… SUCCESS' if attempt.get('success') else 'â„¹ï¸ INFO'}
Payload: {attempt.get('payload', 'N/A')}
Description: {attempt.get('description', 'N/A')}
Source: {attempt.get('source', 'Unknown')}
"""
            
            self.details_output.setText(details)
        except Exception as e:
            logger.error(f"Display results error: {e}")
    
    def _display_ai_results(self, result: dict):
        """Display AI test results"""
        try:
            self.results_table.setRowCount(0)
            
            # Handle both old format (results) and new format (findings/all_results)
            items_to_display = result.get('all_results', result.get('findings', result.get('results', [])))
            
            for finding in items_to_display:
                row = self.results_table.rowCount()
                self.results_table.insertRow(row)
                
                # Determine if vulnerable
                is_vulnerable = finding.get('vulnerable') or finding.get('status') == 'VULNERABLE'
                status_text = "ðŸš¨ VULNERABLE" if is_vulnerable else "âœ“ PASS"
                
                items = [
                    finding.get('title', finding.get('test_name', 'Unknown')),
                    finding.get('id', finding.get('test_id', '')),
                    status_text,
                    f"Code: {finding.get('http_evidence', {}).get('status_code', finding.get('response_code', 'N/A'))}",
                    ' | '.join(finding.get('proof_points', ['N/A'])[:2])[:50],
                    finding.get('confidence', 'N/A')
                ]
                
                for col, item in enumerate(items):
                    cell = QTableWidgetItem(str(item))
                    # Color vulnerable tests red, passed tests green
                    if is_vulnerable:
                        cell.setBackground(QColor(255, 100, 100))  # Red for vulnerable
                    else:
                        cell.setBackground(QColor(100, 255, 100))  # Green for passed
                    self.results_table.setItem(row, col, cell)
            
            # Detailed output with both formats
            details = f"""
AI VULNERABILITY TEST RESULTS
Target: {result.get('target', 'Unknown')}
Timestamp: {time.ctime(result.get('timestamp', time.time()))}
Status: {result.get('status', 'Unknown').upper()}

SUMMARY:
Total Tests: {result.get('total_tests_run', result.get('total_tests', 0))}
Vulnerabilities Found: {result.get('total_vulnerabilities', result.get('vulnerabilities_found', 0))}
Success Rate: {result.get('success_rate', 'N/A')}
Avg Response Time: {result.get('avg_response_time', 'N/A')}

SEVERITY BREAKDOWN:
"""
            
            severity_summary = result.get('severity_summary', {})
            for sev, count in severity_summary.items():
                if count > 0:
                    details += f"  {sev}: {count}\n"
            
            # Summary of all tests
            passed_count = sum(1 for f in items_to_display if not f.get('vulnerable') and f.get('status') == 'PASS')
            failed_count = sum(1 for f in items_to_display if f.get('vulnerable') or f.get('status') == 'VULNERABLE')
            
            details += f"""
TEST SUMMARY:
  Passed: {passed_count}
  Failed: {failed_count}
  Total: {len(items_to_display)}

VULNERABLE TESTS:
"""
            
            # Show details for vulnerable findings
            vulnerable_findings = [f for f in items_to_display if f.get('vulnerable') or f.get('status') == 'VULNERABLE']
            
            if vulnerable_findings:
                for finding in vulnerable_findings:
                    details += f"""
            TEST: {finding.get('title', finding.get('test_name', 'Unknown'))}
            ID: {finding.get('id', finding.get('test_id', 'N/A'))}
            Type: {finding.get('type', finding.get('test_type', 'N/A'))}
            Severity: {finding.get('severity', 'N/A')}
            Confidence: {finding.get('confidence', 'N/A')}

            Description:
            {finding.get('description', 'N/A')}

            Impact:
            {finding.get('impact', 'N/A')}

            Proof Points:
            """
                    for proof in finding.get('proof_points', []):
                        details += f"  - {proof}\n"
                    
                    # Show HTTP evidence if available
                    http_ev = finding.get('http_evidence', {})
                    if http_ev:
                        details += f"""
            HTTP Evidence:
            URL: {http_ev.get('url', 'N/A')}
            Method: {http_ev.get('method', 'GET')}
            Status: {http_ev.get('status_code', 'N/A')}
            Response Time: {http_ev.get('response_time', 'N/A')}
            Headers ({len(http_ev.get('headers', {}))} total):
            """
                        for header, value in list(http_ev.get('headers', {}).items())[:5]:
                            details += f"    {header}: {value}\n"
                        if len(http_ev.get('headers', {})) > 5:
                            details += f"    ... and {len(http_ev.get('headers', {})) - 5} more headers\n"
                    
                    details += f"""
            Remediation:
            {finding.get('remediation', 'See recommendations section')}
            """
            else:
                details += "\n[No vulnerabilities found in automated scanning]\n"
            
            if self.ai_tester:
                remediation = self.ai_tester.get_remediation_recommendations()
                details += f"""

REMEDIATION RECOMMENDATIONS:

CRITICAL ISSUES:
"""
                for rec in remediation.get('critical', []):
                    details += f"\n{rec['vulnerability']}\nFix: {rec['fix']}\n"
                
                details += """
HIGH PRIORITY:
"""
                for rec in remediation.get('high', []):
                    details += f"\n{rec['vulnerability']}\nFix: {rec['fix']}\n"
            
            details += f"""

AI Testing Complete - {time.ctime()}
For authorized testing only - ensure proper authorization
"""
            
            self.details_output.setText(details)
            
        except Exception as e:
            logger.error(f"Display AI results error: {e}")
            import traceback
            traceback.print_exc()
    
    def _refresh_shared_exploits(self):
        """Refresh exploits from network"""
        if not self.exploit_sharer:
            return
        
        stats = self.exploit_sharer.get_network_statistics()
        
        self.stats_label.setText(
            f"Network Stats: {stats['total_exploits']} exploits, "
            f"{stats['critical_count']} critical, "
            f"{stats['high_count']} high"
        )
        
        self.network_list.clear()
        
        all_exploits = (
            self.exploit_sharer.registry.get_all_exploits() +
            list(self.exploit_sharer.received_exploits.values())
        )
        
        for exploit in sorted(all_exploits, 
                             key=lambda e: {'Critical': 0, 'High': 1, 'Medium': 2, 'Low': 3}.get(e.severity, 4)):
            item_text = f"[{exploit.severity}] {exploit.exploit_type} - {exploit.target_url}"
            item = QListWidgetItem(item_text)
            
            if exploit.severity == 'Critical':
                item.setBackground(QColor(255, 100, 100))
            elif exploit.severity == 'High':
                item.setBackground(QColor(255, 165, 0))
            
            self.network_list.addItem(item)
    
    def _export_results(self):
        """Export current results"""
        if not self.current_search_results and not self.current_ai_results:
            QMessageBox.warning(self, "No Results", "No search results to export")
            return
        
        filename = self.exploit_sharer.export_exploits()
        QMessageBox.information(self, "Exported", f"Results exported to {filename}")
    
    def _export_security_report(self):
        """Export comprehensive security analysis report for HackerOne/bug bounty platforms"""
        if not self.current_search_results and not self.current_ai_results:
            QMessageBox.warning(self, "No Results", "No vulnerabilities found to report")
            return
        
        try:
            report = self._generate_hackerone_report()
            
            # Export to JSON for structured submission
            timestamp = int(time.time())
            json_filename = f"security_report_{timestamp}.json"
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # Export to Markdown for human review
            md_filename = f"security_report_{timestamp}.md"
            with open(md_filename, 'w', encoding='utf-8') as f:
                f.write(self._generate_markdown_report(report))
            
            # Export to HTML for professional presentation
            html_filename = f"security_report_{timestamp}.html"
            with open(html_filename, 'w', encoding='utf-8') as f:
                f.write(self._generate_html_report(report))
            
            QMessageBox.information(
                self, 
                "Report Exported", 
                f"Security report exported successfully:\n\n"
                f"- {json_filename}\n"
                f"- {md_filename}\n"
                f"- {html_filename}"
            )
        except Exception as e:
            logger.error(f"Report export error: {e}")
            QMessageBox.critical(self, "Export Error", f"Failed to export report: {str(e)}")
    
    def _generate_hackerone_report(self) -> dict:
        """Generate HackerOne-compatible security report"""
        report = {
            "report_type": "vulnerability_disclosure",
            "report_version": "1.0",
            "generated_at": time.time(),
            "generated_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "target": self.url_input.text() or "Unknown",
            "severity_summary": {},
            "findings": [],
            "recommendations": [],
            "metadata": {
                "tool": "HadesAI Security Analysis",
                "scanner_version": "1.0",
                "authorization_note": "Testing authorized for this target"
            }
        }
        
        # Collect all findings
        all_findings = []
        
        # Add exploit seek findings
        for attempt in self.current_search_results.get('attempts', []):
            if attempt.get('success') or attempt.get('severity') in ['Critical', 'High']:
                # Ensure confidence is properly converted to float
                conf = attempt.get('confidence', 0.5)
                try:
                    if isinstance(conf, str):
                        conf = float(conf.rstrip('%'))
                        if conf > 1:
                            conf = conf / 100.0
                    else:
                        conf = float(conf)
                except (ValueError, TypeError):
                    conf = 0.5
                
                # Extract non-sensitive proof points
                proof_points = self._extract_proof_points(attempt)
                
                finding = {
                    "id": attempt.get('exploit_id', f"exploit_{len(all_findings) + 1}"),
                    "type": attempt.get('exploit_type', 'Unknown'),
                    "severity": attempt.get('severity', 'Medium'),
                    "title": f"{attempt.get('exploit_type', 'Unknown')} Vulnerability",
                    "description": attempt.get('description', ''),
                    "payload": attempt.get('payload', ''),
                    "impact": attempt.get('impact', ''),
                    "remediation": attempt.get('remediation', ''),
                    "confidence": conf,
                    "source": attempt.get('source', 'Exploit Database'),
                    "status": "Confirmed" if attempt.get('success') else "Potential",
                    "proof_points": proof_points,
                    "proof_of_concept": {
                        "type": "payload",
                        "content": attempt.get('payload', '')
                    }
                }
                all_findings.append(finding)
        
        # Add AI vulnerability test findings
        for test in self.current_ai_results.get('results', []):
            if test.get('vulnerable'):
                # Ensure confidence is properly converted for severity mapping
                conf = test.get('confidence', 0)
                try:
                    if isinstance(conf, str):
                        conf = float(conf.rstrip('%'))
                        if conf > 1:
                            conf = conf / 100.0
                    else:
                        conf = float(conf)
                except (ValueError, TypeError):
                    conf = 0
                
                # Extract non-sensitive proof points from test
                proof_points = self._extract_ai_proof_points(test)
                
                finding = {
                    "id": test.get('test_id', f"ai_vuln_{len(all_findings) + 1}"),
                    "type": test.get('test_name', 'Unknown'),
                    "severity": self._map_confidence_to_severity(conf),
                    "title": test.get('test_name', 'Unknown Vulnerability'),
                    "description": f"AI detected vulnerability during automated testing",
                    "evidence": test.get('evidence', ''),
                    "payload": test.get('payload', ''),
                    "response_code": test.get('response_code', 'N/A'),
                    "confidence": conf,
                    "source": "AI Vulnerability Tester",
                    "status": "Confirmed",
                    "proof_points": proof_points,
                    "proof_of_concept": {
                        "type": "http_response",
                        "response_code": test.get('response_code', 'N/A'),
                        "evidence": test.get('evidence', '')
                    }
                }
                all_findings.append(finding)
        
        # Build severity summary
        severity_count = {}
        for finding in all_findings:
            sev = finding.get('severity', 'Medium')
            severity_count[sev] = severity_count.get(sev, 0) + 1
        
        report["severity_summary"] = severity_count
        report["findings"] = all_findings
        report["total_vulnerabilities"] = len(all_findings)
        
        # Generate recommendations
        recommendations = self._generate_remediation_recommendations(all_findings)
        report["recommendations"] = recommendations
        
        return report
    
    def _extract_proof_points(self, attempt: dict) -> List[str]:
        """Extract non-sensitive proof points from exploit attempt"""
        proof_points = []
        
        # Add vulnerability-specific indicators
        exploit_type = attempt.get('exploit_type', '').lower()
        description = attempt.get('description', '').lower()
        
        # SQL Injection indicators
        if 'sql' in exploit_type or 'injection' in exploit_type:
            if attempt.get('success'):
                proof_points.append("Database responded to injection payload")
                proof_points.append("SQL query execution confirmed")
            else:
                if 'error' in description:
                    proof_points.append("Database error message revealed in response")
                proof_points.append("Parameter accepted injection syntax")
        
        # XSS indicators
        if 'xss' in exploit_type or 'cross' in exploit_type:
            if attempt.get('success'):
                proof_points.append("Script payload reflected in HTML response")
                proof_points.append("No output encoding detected")
            else:
                proof_points.append("HTML injection possible via parameter")
                proof_points.append("User input not properly sanitized")
        
        # Authentication bypass
        if 'auth' in exploit_type or 'bypass' in exploit_type:
            if attempt.get('success'):
                proof_points.append("Unauthenticated access to protected resource")
                proof_points.append("Session validation bypassed")
            else:
                proof_points.append("Authentication mechanism found to be weak")
                proof_points.append("Default credentials may exist")
        
        # Configuration/Information disclosure
        if 'config' in exploit_type or 'debug' in exploit_type or 'exposure' in exploit_type:
            proof_points.append("Sensitive path/interface publicly accessible")
            if 'admin' in description:
                proof_points.append("Admin panel discovered without authentication")
            if 'debug' in description:
                proof_points.append("Debug mode or verbose errors enabled")
        
        # Generic behavioral indicators
        if attempt.get('success'):
            proof_points.append(f"Payload executed successfully")
            proof_points.append(f"Target responded with exploitation indicators")
        
        # Response-based evidence (non-sensitive)
        if attempt.get('response_code'):
            code = str(attempt.get('response_code'))
            if code.startswith('200'):
                proof_points.append("Target returned HTTP 200 (unexpected for normal request)")
            elif code.startswith('302'):
                proof_points.append("Target performed redirect to protected area")
            elif code.startswith('401') or code.startswith('403'):
                proof_points.append("Authentication required but method to bypass found")
        
        # Return unique proof points
        return list(set(proof_points)) if proof_points else ["Vulnerability detected during scanning"]
    
    def _extract_ai_proof_points(self, test: dict) -> List[str]:
        """Extract non-sensitive proof points from AI vulnerability test"""
        proof_points = []
        
        test_name = test.get('test_name', '').lower()
        response_code = test.get('response_code')
        evidence = test.get('evidence', '').lower()
        
        # Response code analysis
        if response_code:
            code = str(response_code)
            if code == '200':
                proof_points.append("Unexpected HTTP 200 response to test request")
            elif code == '500':
                proof_points.append("Server error triggered by test payload")
            elif code == '403':
                proof_points.append("Authentication bypass indicator - 403 not enforced")
            elif code in ['401', '302']:
                proof_points.append(f"Server returned {code} - authentication weakness found")
        
        # Test-specific indicators
        if 'sql' in test_name or 'injection' in test_name:
            proof_points.append("Database parameter vulnerable to injection syntax")
            if 'union' in test_name:
                proof_points.append("UNION-based SQL injection possible")
        
        if 'xss' in test_name or 'cross' in test_name:
            if 'event' in test_name:
                proof_points.append("Event handler injection accepted by application")
            proof_points.append("Script payload not filtered from output")
        
        if 'auth' in test_name or 'default' in test_name:
            proof_points.append("Authentication weakness detected")
            if 'bypass' in test_name:
                proof_points.append("Authentication controls can be circumvented")
        
        if 'header' in test_name or 'missing' in test_name:
            proof_points.append("Security headers not properly configured")
            proof_points.append("HTTP response lacks protective controls")
        
        if 'admin' in test_name or 'panel' in test_name:
            proof_points.append("Admin interface accessible without authorization")
        
        if 'debug' in test_name:
            proof_points.append("Debug mode or verbose error messages enabled")
        
        # Path traversal indicators
        if 'path' in test_name or 'traversal' in test_name or 'lfi' in test_name:
            proof_points.append("Application accepted path traversal sequences")
            proof_points.append("System files potentially accessible via traversal")
        
        # Access control indicators
        if 'acl' in test_name or 'privilege' in test_name:
            proof_points.append("Authorization checks not properly enforced")
            proof_points.append("Privilege escalation possible without proper validation")
            proof_points.append("Access control lists bypassed")
        
        # Cookie security indicators
        if 'cookie' in test_name or 'session' in test_name:
            if 'httponly' in test_name:
                proof_points.append("HttpOnly flag missing - cookies accessible to JavaScript")
            if 'secure' in test_name:
                proof_points.append("Secure flag missing - cookies sent over insecure connections")
            if 'fixation' in test_name:
                proof_points.append("Session fixation vulnerability - custom session IDs accepted")
        
        # Memory safety indicators
        if 'buffer' in test_name or 'overflow' in test_name or 'memory' in test_name:
            proof_points.append("Application vulnerable to memory corruption")
            proof_points.append("Buffer boundaries not properly validated")
        
        # Object reference indicators
        if 'object' in test_name or 'idor' in test_name:
            proof_points.append("Direct object references accessible without authorization")
            proof_points.append("Private variables exposed via public API")
        
        # Enumeration indicators
        if 'enumeration' in test_name or 'enum' in test_name:
            proof_points.append("Application reveals information about existing accounts")
            proof_points.append("Timing-based vulnerabilities in authentication flow")
        
        # Fingerprinting indicators
        if 'fingerprint' in test_name or 'version' in test_name or 'framework' in test_name:
            proof_points.append("Server technology stack disclosed in responses")
            proof_points.append("Framework and version information exposed")
            proof_points.append("Operating system details revealed")
        
        # File upload indicators
        if 'upload' in test_name or 'file' in test_name:
            proof_points.append("Unrestricted file upload vulnerability confirmed")
            if 'extension' in test_name:
                proof_points.append("File extension validation bypassed")
            if 'web root' in test_name or 'webroot' in test_name:
                proof_points.append("Malicious files uploadable to web-accessible directory")
        
        # CSRF indicators
        if 'csrf' in test_name or 'forgery' in test_name or 'spoofing' in test_name:
            proof_points.append("CSRF protections not properly implemented")
            proof_points.append("Cross-site request forgery possible")
        
        # AJAX/API indicators
        if 'ajax' in test_name or 'api' in test_name:
            proof_points.append("API endpoints vulnerable to unauthorized access")
            proof_points.append("AJAX requests not properly validated")
            if 'endpoint' in test_name or 'enumeration' in test_name:
                proof_points.append("All API endpoints discoverable and enumerable")
        
        # CVE indicators
        if 'cve' in test_name:
            proof_points.append("Known CVE vulnerability present in application")
            if 'log4' in test_name or 'log4shell' in test_name:
                proof_points.append("Log4j vulnerable version confirmed")
            if 'struts' in test_name:
                proof_points.append("Apache Struts OGNL injection vulnerability")
            if 'spring' in test_name:
                proof_points.append("Spring Framework classloader injection vulnerability")
            if 'shellshock' in test_name:
                proof_points.append("Bash ShellShock vulnerability confirmed")
        
        # Evidence-based indicators (sanitized)
        if evidence:
            if 'html' in evidence or 'title' in evidence:
                proof_points.append("Response contained HTML title/structure from protected area")
            if 'set-cookie' in evidence:
                proof_points.append("Authenticated session created without proper checks")
            if 'admin' in evidence:
                proof_points.append("Admin-level content returned in response")
            if 'error' in evidence or 'exception' in evidence:
                proof_points.append("Server error details exposed in response")
            if 'passwd' in evidence or 'windows' in evidence:
                proof_points.append("System configuration files accessible")
        
        # Return unique proof points
        return list(set(proof_points)) if proof_points else ["Vulnerability confirmed by AI testing"]
    
    def _map_confidence_to_severity(self, confidence) -> str:
        """Map AI confidence score to severity level"""
        try:
            # Convert to float if string
            if isinstance(confidence, str):
                # Handle percentage strings like "80%" or "0.8"
                confidence = confidence.rstrip('%')
                conf_val = float(confidence)
                # If it's a percentage (> 1), convert to decimal
                if conf_val > 1:
                    conf_val = conf_val / 100.0
            else:
                conf_val = float(confidence)
        except (ValueError, TypeError):
            # Default to medium if can't convert
            return "Medium"
        
        if conf_val >= 0.9:
            return "Critical"
        elif conf_val >= 0.7:
            return "High"
        elif conf_val >= 0.5:
            return "Medium"
        else:
            return "Low"
    
    def _generate_remediation_recommendations(self, findings: List[dict]) -> List[dict]:
        """Generate remediation recommendations based on findings"""
        recommendations = []
        
        # Group findings by type
        by_type = {}
        for finding in findings:
            ftype = finding.get('type', 'Unknown')
            if ftype not in by_type:
                by_type[ftype] = []
            by_type[ftype].append(finding)
        
        # Generate recommendations
        for ftype, vulns in by_type.items():
            highest_severity = max([v.get('severity', 'Low') for v in vulns], 
                                  key=lambda x: {'Critical': 4, 'High': 3, 'Medium': 2, 'Low': 1}.get(x, 0))
            
            rec = {
                "vulnerability_type": ftype,
                "affected_count": len(vulns),
                "highest_severity": highest_severity,
                "recommendations": []
            }
            
            # Type-specific remediation
            if 'injection' in ftype.lower() or 'sql' in ftype.lower():
                rec["recommendations"] = [
                    "Implement parameterized queries/prepared statements",
                    "Use ORM frameworks with built-in SQL escaping",
                    "Validate and sanitize all user inputs",
                    "Apply principle of least privilege to database accounts"
                ]
            elif 'xss' in ftype.lower() or 'cross' in ftype.lower():
                rec["recommendations"] = [
                    "Implement Content Security Policy (CSP) headers",
                    "Use HTML entity encoding for user-supplied content",
                    "Apply context-aware output encoding",
                    "Use modern JavaScript frameworks with XSS protection"
                ]
            elif 'auth' in ftype.lower():
                rec["recommendations"] = [
                    "Implement multi-factor authentication (MFA)",
                    "Enforce strong password policies",
                    "Disable default credentials immediately",
                    "Implement rate limiting on authentication endpoints",
                    "Use secure session management"
                ]
            elif 'config' in ftype.lower() or 'exposure' in ftype.lower():
                rec["recommendations"] = [
                    "Disable debug mode in production",
                    "Remove unnecessary admin panels",
                    "Implement proper access controls",
                    "Restrict directory listing",
                    "Remove backup files from web root"
                ]
            elif 'header' in ftype.lower() or 'cors' in ftype.lower():
                rec["recommendations"] = [
                    "Implement security headers (CSP, X-Frame-Options, etc.)",
                    "Configure CORS correctly",
                    "Enable HSTS",
                    "Set X-Content-Type-Options: nosniff"
                ]
            else:
                rec["recommendations"] = [
                    "Review vulnerability details carefully",
                    "Implement vendor recommendations",
                    "Apply security patches promptly",
                    "Conduct security audit"
                ]
            
            recommendations.append(rec)
        
        return recommendations
    
    def _generate_markdown_report(self, report: dict) -> str:
        """Generate Markdown format report for HackerOne"""
        md = f"""# Security Analysis Report

**Report Type:** {report['report_type']}  
**Generated:** {report['generated_date']}  
**Target:** {report['target']}  
**Tool:** {report['metadata']['tool']}

## Executive Summary

This security analysis report documents vulnerabilities discovered during comprehensive testing of the target application. A total of **{report['total_vulnerabilities']} vulnerabilities** were identified across various categories.

### Severity Breakdown

"""
        
        severity_counts = report.get('severity_summary', {})
        for severity in ['Critical', 'High', 'Medium', 'Low']:
            count = severity_counts.get(severity, 0)
            if count > 0:
                md += f"- **{severity}:** {count}\n"
        
        md += "\n## Detailed Findings\n"
        
        for i, finding in enumerate(report.get('findings', []), 1):
            md += f"""
### Finding #{i}: {finding.get('title', 'Unknown')}

**ID:** {finding.get('id')}  
**Type:** {finding.get('type')}  
**Severity:** {finding.get('severity')}  
**Status:** {finding.get('status')}  
**Confidence:** {finding.get('confidence', 'N/A')}

#### Description

{finding.get('description', 'No description available')}

#### Affected Component

{finding.get('source', 'Unknown')}

#### Impact

{finding.get('impact', 'Potential security compromise')}

#### Evidence & Proof Points

"""
            for proof_point in finding.get('proof_points', []):
                md += f"- {proof_point}\n"
            
            md += f"""

#### Proof of Concept

```
{finding.get('payload', 'N/A')}
```

#### Remediation

{finding.get('remediation', 'See recommendations section below')}

---
"""
        
        md += "\n## Recommendations\n\n"
        
        for rec in report.get('recommendations', []):
            md += f"""### {rec['vulnerability_type']}

**Affected Issues:** {rec['affected_count']}  
**Highest Severity:** {rec['highest_severity']}

**Remediation Steps:**

"""
            for step in rec.get('recommendations', []):
                md += f"- {step}\n"
            
            md += "\n"
        
        md += f"""
## Disclaimer

This report contains security testing results for authorized testing only. Unauthorized access to computer systems is illegal. Ensure proper authorization has been obtained before conducting security testing.

**Authorization Note:** {report['metadata']['authorization_note']}

---

*Report Generated by {report['metadata']['tool']} v{report['metadata']['scanner_version']}*
"""
        
        return md
    
    def _generate_html_report(self, report: dict) -> str:
        """Generate HTML format report for professional presentation"""
        severity_colors = {
            'Critical': '#d32f2f',
            'High': '#f57c00',
            'Medium': '#fbc02d',
            'Low': '#388e3c'
        }
        
        html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Security Analysis Report</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }}
        .container {{
            max-width: 900px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }}
        .header {{
            border-bottom: 3px solid #1976d2;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }}
        h1 {{
            color: #1976d2;
            margin-bottom: 10px;
        }}
        h2 {{
            color: #1976d2;
            margin-top: 30px;
            margin-bottom: 15px;
            border-left: 4px solid #1976d2;
            padding-left: 10px;
        }}
        h3 {{
            color: #333;
            margin-top: 20px;
            margin-bottom: 10px;
        }}
        .meta {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
            font-size: 14px;
        }}
        .meta-item {{
            background: #f9f9f9;
            padding: 10px;
            border-left: 3px solid #1976d2;
        }}
        .meta-label {{
            font-weight: bold;
            color: #1976d2;
        }}
        .summary {{
            background: #e3f2fd;
            padding: 20px;
            border-radius: 4px;
            margin-bottom: 20px;
        }}
        .severity-grid {{
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 15px;
            margin: 15px 0;
        }}
        .severity-card {{
            padding: 15px;
            border-radius: 4px;
            color: white;
            text-align: center;
            font-weight: bold;
        }}
        .critical {{ background: {severity_colors['Critical']}; }}
        .high {{ background: {severity_colors['High']}; }}
        .medium {{ background: {severity_colors['Medium']}; }}
        .low {{ background: {severity_colors['Low']}; }}
        .finding {{
            background: #fafafa;
            border: 1px solid #ddd;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 4px;
            border-left: 4px solid #999;
        }}
        .critical.finding {{ border-left-color: {severity_colors['Critical']}; }}
        .high.finding {{ border-left-color: {severity_colors['High']}; }}
        .medium.finding {{ border-left-color: {severity_colors['Medium']}; }}
        .low.finding {{ border-left-color: {severity_colors['Low']}; }}
        .finding-title {{
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 10px;
        }}
        .finding-meta {{
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
            margin-bottom: 15px;
            font-size: 13px;
        }}
        .finding-meta-item {{
            background: white;
            padding: 8px;
            border-radius: 3px;
            border-left: 2px solid #1976d2;
        }}
        .finding-meta-label {{
            font-weight: bold;
            color: #1976d2;
        }}
        .poc {{
            background: #f0f0f0;
            border: 1px solid #ddd;
            padding: 15px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            overflow-x: auto;
            margin: 10px 0;
        }}
        .recommendations {{
            background: #f1f8e9;
            padding: 20px;
            border-radius: 4px;
            margin: 15px 0;
        }}
        .recommendations ul {{
            margin-left: 20px;
        }}
        .recommendations li {{
            margin-bottom: 8px;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            font-size: 12px;
            color: #666;
            text-align: center;
        }}
        .disclaimer {{
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 20px 0;
            border-radius: 3px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ðŸ”’ Security Analysis Report</h1>
            <p>Comprehensive vulnerability assessment and findings</p>
        </div>
        
        <div class="meta">
            <div class="meta-item">
                <span class="meta-label">Report ID:</span>
                {report['generated_at']}
            </div>
            <div class="meta-item">
                <span class="meta-label">Generated:</span>
                {report['generated_date']}
            </div>
            <div class="meta-item">
                <span class="meta-label">Target:</span>
                {report['target']}
            </div>
            <div class="meta-item">
                <span class="meta-label">Scanner:</span>
                {report['metadata']['tool']}
            </div>
        </div>
        
        <div class="summary">
            <h2>Executive Summary</h2>
            <p>This security analysis identified <strong>{report['total_vulnerabilities']} vulnerabilities</strong> during comprehensive testing of the target application.</p>
            
            <div class="severity-grid">
"""
        
        severity_counts = report.get('severity_summary', {})
        for severity in ['Critical', 'High', 'Medium', 'Low']:
            count = severity_counts.get(severity, 0)
            if count > 0:
                html += f'<div class="severity-card {severity.lower()}">{severity}<br>{count} Issues</div>\n'
        
        html += """
            </div>
        </div>
        
        <h2>Findings</h2>
"""
        
        for i, finding in enumerate(report.get('findings', []), 1):
            sev_class = finding.get('severity', 'Medium').lower()
            html += f"""
        <div class="finding {sev_class}">
            <div class="finding-title">#{i} {finding.get('title', 'Unknown Vulnerability')}</div>
            
            <div class="finding-meta">
                <div class="finding-meta-item">
                    <span class="finding-meta-label">ID:</span>
                    {finding.get('id')}
                </div>
                <div class="finding-meta-item">
                    <span class="finding-meta-label">Type:</span>
                    {finding.get('type')}
                </div>
                <div class="finding-meta-item">
                    <span class="finding-meta-label">Severity:</span>
                    {finding.get('severity')}
                </div>
            </div>
            
            <div class="finding-meta">
                <div class="finding-meta-item">
                    <span class="finding-meta-label">Status:</span>
                    {finding.get('status')}
                </div>
                <div class="finding-meta-item">
                    <span class="finding-meta-label">Confidence:</span>
                    {finding.get('confidence', 'N/A')}
                </div>
                <div class="finding-meta-item">
                    <span class="finding-meta-label">Source:</span>
                    {finding.get('source', 'Unknown')}
                </div>
            </div>
            
            <h4>Description</h4>
            <p>{finding.get('description', 'No description available')}</p>
            
            <h4>Impact</h4>
            <p>{finding.get('impact', 'Potential security compromise')}</p>
            
            <h4>Evidence & Proof Points</h4>
            <ul style="margin-left: 20px; margin-bottom: 15px;">
"""
        for proof_point in finding.get('proof_points', []):
            html += f"                <li>{proof_point}</li>\n"
        
        html += f"""
            </ul>
            
            <h4>Proof of Concept</h4>
            <div class="poc">{finding.get('payload', 'N/A')}</div>
            
            <h4>Remediation</h4>
            <p>{finding.get('remediation', 'See recommendations section')}</p>
        </div>
"""
        
        html += """
        <h2>Remediation Recommendations</h2>
"""
        
        for rec in report.get('recommendations', []):
            html += f"""
        <h3>{rec['vulnerability_type']}</h3>
        <p><strong>Affected Issues:</strong> {rec['affected_count']} | <strong>Severity:</strong> {rec['highest_severity']}</p>
        
        <div class="recommendations">
            <strong>Recommended Actions:</strong>
            <ul>
"""
            for step in rec.get('recommendations', []):
                html += f"                <li>{step}</li>\n"
            
            html += """
            </ul>
        </div>
"""
        
        html += f"""
        <div class="disclaimer">
            <strong>âš ï¸ Disclaimer:</strong> This report contains results from authorized security testing only. Unauthorized access to computer systems is illegal. {report['metadata']['authorization_note']}
        </div>
        
        <div class="footer">
            Generated by {report['metadata']['tool']} v{report['metadata']['scanner_version']}
        </div>
    </div>
</body>
</html>
"""
        
        return html
    
    def _share_to_network(self):
        """Share current results to P2P network"""
        if not self.exploit_sharer.network_node:
            QMessageBox.warning(self, "Network Unavailable", 
                              "P2P network not configured. Enable Network Sharing first.")
            return
        
        attempts = self.current_search_results.get('attempts', [])
        if not attempts:
            QMessageBox.warning(self, "No Results", "No exploits to share")
            return
        
        count = 0
        for attempt in attempts:
            if attempt.get('success'):
                exploit = ExploitFinding(
                    exploit_id=f"{attempt['exploit_id']}_{int(time.time())}",
                    target_url=self.current_search_results.get('target', ''),
                    exploit_type=attempt.get('exploit_type', ''),
                    severity='Critical' if attempt.get('success') else 'High',
                    payload=attempt.get('payload', ''),
                    description=f"Successful exploit discovered via seek",
                    timestamp=time.time(),
                    instance_id=self.exploit_sharer.instance_id,
                    success=True
                )
                self.exploit_sharer.register_exploit(exploit)
                count += 1
        
        QMessageBox.information(self, "Shared", f"{count} exploits shared to network")
    
    def _clear_results(self):
        """Clear results"""
        self.results_table.setRowCount(0)
        self.details_output.clear()
        self.url_input.clear()
        self.current_search_results = {}
        self.current_ai_results = {}
        self.status_label.setText("Ready")
        self.status_label.setStyleSheet("color: #4CAF50; font-weight: bold;")


def create_exploit_seek_tab(parent=None, exploit_sharer: P2PExploitSharer = None, hades_ai=None) -> ExploitSeekTab:
    """Factory function to create exploit seek tab with all available knowledge sources"""
    return ExploitSeekTab(parent, exploit_sharer, hades_ai)
