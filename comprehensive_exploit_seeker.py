"""
Comprehensive Exploit Seeker
Pulls from ALL available knowledge sources:
- P2P network exploits
- Local exploit registry
- KnowledgeBase learned exploits
- Cognitive memory recalls
- Attack vectors database
- Threat findings database
"""

import logging
import sqlite3
import time
from typing import Dict, List, Optional, Callable
from datetime import datetime
from p2p_exploit_sharing import P2PExploitSharer, ExploitFinding

try:
    from threat_type_enum import ThreatType, get_threat_severity, get_threat_category, get_threat_remediation
    HAS_THREAT_ENUM = True
except ImportError:
    ThreatType = None
    HAS_THREAT_ENUM = False
    def get_threat_severity(x): return "Medium"
    def get_threat_category(x): return "Unknown"
    def get_threat_remediation(x): return "Investigate and remediate"

logger = logging.getLogger("ComprehensiveExploitSeeker")


class UnifiedExploitKnowledge:
    """Unified knowledge base aggregating all exploit sources"""
    
    def __init__(self, hades_ai=None, exploit_sharer: P2PExploitSharer = None):
        self.hades_ai = hades_ai  # Main HadesAI instance
        self.exploit_sharer = exploit_sharer  # P2P exploit sharer
        self.kb = hades_ai.kb if hades_ai else None  # KnowledgeBase
        self.cognitive = hades_ai.cognitive if hades_ai else None  # Cognitive layer
        self.source_cache = {}  # Cache for source statistics
        self.last_enumeration = 0
    
    def seek_all_exploits(self, target_url: str) -> List[Dict]:
        """
        Seek exploits from ALL available sources
        Returns unified list of exploits with their source
        """
        all_exploits = []
        source_counts = {}
        
        # Source 1: P2P Network Exploits
        logger.info("Searching P2P network for exploits...")
        p2p_exploits = self._get_p2p_exploits(target_url)
        all_exploits.extend(p2p_exploits)
        source_counts['P2P Network'] = len(p2p_exploits)
        logger.info(f"  -> Found {len(p2p_exploits)} P2P exploits")
        
        # Source 2: Knowledge Base Learned Exploits
        logger.info("Searching learned exploits database...")
        learned_exploits = self._get_learned_exploits(target_url)
        all_exploits.extend(learned_exploits)
        source_counts['Knowledge Base (Learned)'] = len(learned_exploits)
        logger.info(f"  -> Found {len(learned_exploits)} learned exploits")
        
        # Source 3: Threat Findings
        logger.info("Searching threat findings...")
        threat_exploits = self._get_threat_findings(target_url)
        all_exploits.extend(threat_exploits)
        source_counts['Threat Findings'] = len(threat_exploits)
        logger.info(f"  -> Found {len(threat_exploits)} threat findings")
        
        # Source 4: Security Patterns
        logger.info("Searching security patterns...")
        pattern_exploits = self._get_security_patterns(target_url)
        all_exploits.extend(pattern_exploits)
        source_counts['Security Patterns'] = len(pattern_exploits)
        logger.info(f"  -> Found {len(pattern_exploits)} security patterns")
        
        # Source 5: Cognitive Memory Recall
        logger.info("Searching cognitive memory...")
        cognitive_exploits = self._get_cognitive_exploits(target_url)
        all_exploits.extend(cognitive_exploits)
        source_counts['Cognitive Memory'] = len(cognitive_exploits)
        logger.info(f"  -> Found {len(cognitive_exploits)} cognitive exploits")
        
        # Source 6: Attack Vectors
        logger.info("Searching attack vectors...")
        vector_exploits = self._get_attack_vectors(target_url)
        all_exploits.extend(vector_exploits)
        source_counts['Attack Vectors Database'] = len(vector_exploits)
        logger.info(f"  -> Found {len(vector_exploits)} attack vectors")
        
        # Source 7: Network received exploits
        logger.info("Searching network-received exploits...")
        network_exploits = self._get_network_received_exploits(target_url)
        all_exploits.extend(network_exploits)
        source_counts['Network Received'] = len(network_exploits)
        logger.info(f"  -> Found {len(network_exploits)} network-received exploits")
        
        # Cache source statistics
        self.source_cache = source_counts
        self.last_enumeration = time.time()
        
        # Deduplicate by exploit signature
        unique_exploits = self._deduplicate(all_exploits)
        
        # Sort by severity and confidence
        sorted_exploits = sorted(
            unique_exploits,
            key=lambda e: (
                {'Critical': 0, 'High': 1, 'Medium': 2, 'Low': 3}.get(e.get('severity', 'Low'), 4),
                -float(e.get('confidence', 0))
            )
        )
        
        total = sum(source_counts.values())
        logger.info(f"Found {total} total exploits, {len(sorted_exploits)} unique from all sources")
        logger.info(f"Source breakdown: {source_counts}")
        return sorted_exploits
    
    def _get_p2p_exploits(self, target_url: str) -> List[Dict]:
        """Get exploits from P2P network"""
        if not self.exploit_sharer:
            return []
        
        try:
            p2p_exploits = self.exploit_sharer.seek_exploits(target_url)
            return [
                {
                    'id': e.exploit_id,
                    'type': e.exploit_type,
                    'severity': e.severity,
                    'payload': e.payload,
                    'description': e.description,
                    'success': e.success,
                    'confidence': 0.9 if e.success else 0.7,
                    'source': f'P2P Network ({e.instance_id})',
                    'timestamp': e.timestamp,
                    'impact': e.impact,
                    'remediation': e.remediation
                }
                for e in p2p_exploits
            ]
        except Exception as e:
            logger.error(f"Failed to get P2P exploits: {e}")
            return []
    
    def _get_learned_exploits(self, target_url: str) -> List[Dict]:
        """Get exploits from learned exploits database"""
        if not self.kb:
            return []
        
        try:
            cursor = self.kb.conn.cursor()
            cursor.execute("""
                SELECT id, name, description, payload, severity, confidence, cve_id, metadata
                FROM learned_exploits
                WHERE vulnerability_type IS NOT NULL
                ORDER BY confidence DESC
                LIMIT 100
            """)
            
            exploits = []
            for row in cursor.fetchall():
                exploit_id, name, description, payload, severity, confidence, cve_id, metadata = row
                
                # Check if relevant to target
                if self._matches_target(target_url, description, metadata):
                    exploits.append({
                        'id': f'learned_{exploit_id}',
                        'type': name,
                        'severity': severity or 'Medium',
                        'payload': payload or '',
                        'description': description,
                        'success': confidence > 0.7,
                        'confidence': confidence,
                        'source': 'Knowledge Base (Learned)',
                        'timestamp': datetime.now().timestamp(),
                        'impact': '',
                        'remediation': '',
                        'cve': cve_id
                    })
            
            return exploits
        except Exception as e:
            logger.error(f"Failed to get learned exploits: {e}")
            return []
    
    def _get_threat_findings(self, target_url: str) -> List[Dict]:
        """Get exploits from threat findings"""
        if not self.kb:
            return []
        
        try:
            cursor = self.kb.conn.cursor()
            cursor.execute("""
                SELECT path, threat_type, pattern, severity, code_snippet, context
                FROM threat_findings
                ORDER BY severity DESC
                LIMIT 100
            """)
            
            exploits = []
            for row in cursor.fetchall():
                path, threat_type_str, pattern, severity, code_snippet, context = row
                
                # Normalize threat type using enum
                normalized_threat_type = threat_type_str
                if HAS_THREAT_ENUM:
                    threat_enum = ThreatType.from_string(threat_type_str)
                    normalized_threat_type = threat_enum.value
                    # Use enum for severity if not provided
                    if not severity or severity == 'Unknown':
                        severity = get_threat_severity(threat_type_str)
                    remediation = get_threat_remediation(threat_type_str)
                    category = get_threat_category(threat_type_str)
                else:
                    remediation = 'Review and remediate threat'
                    category = 'Unknown'
                
                exploits.append({
                    'id': f'threat_{path}',
                    'type': normalized_threat_type,
                    'category': category,
                    'severity': severity or 'Medium',
                    'payload': pattern or '',
                    'description': f"Threat found in {path}: {context}",
                    'success': True,
                    'confidence': 0.8,
                    'source': 'Threat Findings',
                    'timestamp': datetime.now().timestamp(),
                    'impact': f'Found in {path}',
                    'remediation': remediation
                })
            
            return exploits
        except Exception as e:
            logger.error(f"Failed to get threat findings: {e}")
            return []
    
    def _get_security_patterns(self, target_url: str) -> List[Dict]:
        """Get exploits from security patterns"""
        if not self.kb:
            return []
        
        try:
            cursor = self.kb.conn.cursor()
            cursor.execute("""
                SELECT pattern_id, pattern_type, signature, severity, confidence
                FROM security_patterns
                ORDER BY confidence DESC
                LIMIT 100
            """)
            
            exploits = []
            for row in cursor.fetchall():
                pattern_id, pattern_type_str, signature, severity, confidence = row
                
                # Normalize threat type using enum
                normalized_type = pattern_type_str
                if HAS_THREAT_ENUM:
                    threat_enum = ThreatType.from_string(pattern_type_str)
                    normalized_type = threat_enum.value
                    # Use enum for severity if not provided
                    if not severity or severity == 'Unknown':
                        severity = get_threat_severity(pattern_type_str)
                    remediation = get_threat_remediation(pattern_type_str)
                    category = get_threat_category(pattern_type_str)
                else:
                    remediation = f'Address {pattern_type_str} pattern'
                    category = 'Unknown'
                
                exploits.append({
                    'id': f'pattern_{pattern_id}',
                    'type': normalized_type,
                    'category': category,
                    'severity': severity or 'Medium',
                    'payload': signature,
                    'description': f'Security pattern: {normalized_type}',
                    'success': confidence > 0.75,
                    'confidence': confidence,
                    'source': 'Security Patterns',
                    'timestamp': datetime.now().timestamp(),
                    'impact': f'Pattern: {normalized_type}',
                    'remediation': remediation
                })
            
            return exploits
        except Exception as e:
            logger.error(f"Failed to get security patterns: {e}")
            return []
    
    def _get_cognitive_exploits(self, target_url: str) -> List[Dict]:
        """Get exploits from cognitive memory recall"""
        if not self.cognitive:
            return []
        
        try:
            # Recall memories related to exploits
            memories = self.cognitive.recall(f"exploit {target_url}", top_k=10)
            
            exploits = []
            for memory_text, similarity in memories:
                if 'exploit' in memory_text.lower() or 'vulnerability' in memory_text.lower():
                    exploits.append({
                        'id': f'cognitive_{hash(memory_text)}',
                        'type': 'Cognitive Recall',
                        'severity': 'Medium',
                        'payload': memory_text[:100],
                        'description': memory_text,
                        'success': similarity > 0.6,
                        'confidence': similarity,
                        'source': 'Cognitive Memory',
                        'timestamp': datetime.now().timestamp(),
                        'impact': 'From learned memories',
                        'remediation': 'Review memory content'
                    })
            
            return exploits
        except Exception as e:
            logger.error(f"Failed to get cognitive exploits: {e}")
            return []
    
    def _get_attack_vectors(self, target_url: str) -> List[Dict]:
        """Get potential attack vectors"""
        if not self.hades_ai or not hasattr(self.hades_ai, 'exploitation'):
            return []
        
        try:
            # Get available attack vectors
            attack_vectors = [
                {
                    'id': 'vector_sql_injection',
                    'type': 'sql_injection',
                    'severity': 'Critical',
                    'payload': "' OR '1'='1'--",
                    'description': 'SQL Injection vulnerability',
                    'success': False,
                    'confidence': 0.6,
                    'source': 'Attack Vectors Database',
                    'timestamp': datetime.now().timestamp(),
                    'impact': 'Database compromise',
                    'remediation': 'Use parameterized queries'
                },
                {
                    'id': 'vector_xss',
                    'type': 'xss',
                    'severity': 'High',
                    'payload': '<img src=x onerror="alert(1)">',
                    'description': 'Cross-Site Scripting vulnerability',
                    'success': False,
                    'confidence': 0.5,
                    'source': 'Attack Vectors Database',
                    'timestamp': datetime.now().timestamp(),
                    'impact': 'Session hijacking',
                    'remediation': 'Input validation and encoding'
                },
                {
                    'id': 'vector_rce',
                    'type': 'rce',
                    'severity': 'Critical',
                    'payload': 'command_injection_payload',
                    'description': 'Remote Code Execution vulnerability',
                    'success': False,
                    'confidence': 0.4,
                    'source': 'Attack Vectors Database',
                    'timestamp': datetime.now().timestamp(),
                    'impact': 'Full system compromise',
                    'remediation': 'Strict input validation'
                },
                {
                    'id': 'vector_ssrf',
                    'type': 'ssrf',
                    'severity': 'High',
                    'payload': 'http://169.254.169.254/latest/meta-data/',
                    'description': 'Server-Side Request Forgery vulnerability',
                    'success': False,
                    'confidence': 0.5,
                    'source': 'Attack Vectors Database',
                    'timestamp': datetime.now().timestamp(),
                    'impact': 'Internal network access',
                    'remediation': 'URL whitelisting'
                },
            ]
            
            return attack_vectors
        except Exception as e:
            logger.error(f"Failed to get attack vectors: {e}")
            return []
    
    def _get_network_received_exploits(self, target_url: str) -> List[Dict]:
        """Get exploits received from network peers"""
        if not self.exploit_sharer:
            return []
        
        try:
            # Get all exploits received from network
            received = self.exploit_sharer.received_exploits.values()
            
            exploits = []
            for exploit in received:
                # Filter by target if specified
                if target_url and exploit.target_url != target_url:
                    continue
                
                exploits.append({
                    'id': exploit.exploit_id,
                    'type': exploit.exploit_type,
                    'severity': exploit.severity,
                    'payload': exploit.payload,
                    'description': exploit.description,
                    'success': exploit.success,
                    'confidence': 0.85 if exploit.success else 0.7,
                    'source': f'Network Received ({exploit.instance_id})',
                    'timestamp': exploit.timestamp,
                    'impact': exploit.impact,
                    'remediation': exploit.remediation
                })
            
            return exploits
        except Exception as e:
            logger.error(f"Failed to get network-received exploits: {e}")
            return []
    
    def _matches_target(self, target_url: str, description: str, metadata: str) -> bool:
        """Check if exploit is relevant to target"""
        # Simple matching - can be enhanced
        domain = target_url.lower()
        description = (description or '').lower()
        metadata = (metadata or '').lower()
        
        # Always include if general (no specific target mentioned)
        if not any(x in description + metadata for x in ['target', 'host', 'ip', 'domain']):
            return True
        
        # Check if target mentioned in description
        if domain in description or domain in metadata:
            return True
        
        return True  # Include by default
    
    def _deduplicate(self, exploits: List[Dict]) -> List[Dict]:
        """Remove duplicate exploits based on type and payload"""
        seen = {}
        unique = []
        
        for exploit in exploits:
            # Create a simple key from type and payload
            key = (exploit.get('type', ''), exploit.get('payload', '')[:50])
            
            if key not in seen:
                seen[key] = True
                unique.append(exploit)
        
        return unique
    
    def get_source_stats(self, exploits: List[Dict]) -> Dict[str, int]:
        """Get statistics about exploit sources from enumeration results"""
        # Return the cached source counts from last enumeration
        # This includes all sources (even those with 0 exploits)
        if self.source_cache:
            return self.source_cache
        
        # Fallback: count from exploits (only sources with results)
        stats = {}
        for exploit in exploits:
            source = exploit.get('source', 'Unknown')
            stats[source] = stats.get(source, 0) + 1
        return stats
    
    def get_enumeration_stats(self) -> Dict[str, int]:
        """Get cached source enumeration stats from last seek"""
        return self.source_cache.copy()


# Integration function for HadesAI
def create_unified_seeker(hades_ai, exploit_sharer: P2PExploitSharer = None) -> UnifiedExploitKnowledge:
    """Create unified exploit seeker connected to HadesAI"""
    return UnifiedExploitKnowledge(hades_ai, exploit_sharer)
